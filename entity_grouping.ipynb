{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine text to include in 'PERSON' entity grouped df\n",
    "trump = ['trump', 'donal trump', '@realdonaldtrump']\n",
    "pelosi = ['pelosi', 'nancy pelosi', '@speakerpelosi']\n",
    "obama = ['obama', 'barack obama', '@barackobama']\n",
    "fauci = ['fauci', 'anthonyfauci']\n",
    "boris = ['boris', 'boris johnson', 'johnson', '@borisjohnson']\n",
    "\n",
    "# 'ORG' entity group text\n",
    "cdc = ['cdc', 'centers for disease control', '@cdcgov']\n",
    "who = ['who', '@who']\n",
    "nhs = ['nhs', 'national health service', '@nhsuk']\n",
    "white_house = ['whitehouse', '@whitehouse', 'white house']\n",
    "congress = ['congress']\n",
    "eu = ['eu', 'european union', 'european commission', '@eu_commission']\n",
    "\n",
    "# 'GPE' entity group text\n",
    "china = ['china', 'chinese']\n",
    "italy = ['italy', 'italian']\n",
    "spain = ['spain', 'spanish']\n",
    "usa = ['usa', 'u.s.', 'america', 'united states']\n",
    "nyc = ['nyc', 'new york', 'newyork']\n",
    "\n",
    "# Some fun entities as well\n",
    "football = ['nfl', 'national football league', 'football', '@nfl']\n",
    "soccer = ['fifa', 'mls', '@mls', 'soccer', '@fifacom', 'premier league', '@premierleague']\n",
    "baseball = ['mlb', 'baseball', '@mlb']\n",
    "basketball = ['nba', 'basketball', '@nba']\n",
    "hockey = ['nhl', 'hockey', '@nhl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_list = [trump, pelosi, obama, fauci, boris, cdc, who, nhs, white_house, congress, eu, china, italy, spain,\n",
    "              usa, nyc, football, soccer, baseball, basketball, hockey]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "\n",
    "def file_grabber(directory):\n",
    "    files = os.listdir(directory)\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file = file.replace('.csv','')\n",
    "            file_list.append(file)\n",
    "\n",
    "file_grabber('data/cleaned_tweet_df/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clean_chunks_7',\n",
       " 'clean_chunks_6',\n",
       " 'small_tweet_set_cleaned',\n",
       " 'clean_chunks_4',\n",
       " 'clean_chunks_5',\n",
       " 'clean_kaggle3',\n",
       " 'clean_chunks_1',\n",
       " 'clean_chunks_0',\n",
       " 'clean_kaggle2',\n",
       " 'clean_chunks_2',\n",
       " 'clean_kaggle1',\n",
       " 'clean_chunks_3']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glob together all the sets of tweet data into a single df to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]//anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (3,4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 36%|███▋      | 4/11 [00:24<00:42,  6.12s/it]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a73fcc4c09c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/cleaned_tweet_df/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#    try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mall_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#    except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#        bad_tweet_dfs.append(file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "all_tweets = []\n",
    "bad_tweet_dfs = []\n",
    "for file in tqdm(glob.glob('data/cleaned_tweet_df/*')):\n",
    "#    try:\n",
    "    all_tweets.append(pd.read_csv(file))\n",
    "#    except:\n",
    "#        bad_tweet_dfs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/cleaned_tweet_df/clean_kaggle3.csv',\n",
       " 'data/cleaned_tweet_df/clean_kaggle2.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_tweet_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                        created_at            id  \\\n",
       " 0        2020-03-16 11:22:34+00:00  1.239512e+18   \n",
       " 1        2020-03-16 11:50:35+00:00  1.239519e+18   \n",
       " 2        2020-03-16 14:51:29+00:00  1.239565e+18   \n",
       " 3        2020-03-17 00:25:56+00:00  1.239710e+18   \n",
       " 4        2020-03-18 22:18:32+00:00  1.240402e+18   \n",
       " ...                            ...           ...   \n",
       " 3641864  2020-03-22 19:14:17+00:00  1.241805e+18   \n",
       " 3641865  2020-03-22 22:46:12+00:00  1.241859e+18   \n",
       " 3641866  2020-03-24 03:58:23+00:00  1.242300e+18   \n",
       " 3641867  2020-03-24 08:16:37+00:00  1.242365e+18   \n",
       " 3641868  2020-03-24 08:49:45+00:00  1.242373e+18   \n",
       " \n",
       "                                                  full_text  geo place lang  \n",
       " 0        RT @XHNews: Heal the wounded and rescue the dy...  NaN   NaN   en  \n",
       " 1        RT @LeftistUnity: *****CORRECTION*****\\n\\nCoro...  NaN   NaN   en  \n",
       " 2        RT @carolecadwalla: Who is the spokesman? Why ...  NaN   NaN   en  \n",
       " 3        RT @KTLA: Watch live: L.A. Mayor Garcetti prov...  NaN   NaN   en  \n",
       " 4        Love #JudiDench 🧡 #COVID19 #KeepSmiling https:...  NaN   NaN   en  \n",
       " ...                                                    ...  ...   ...  ...  \n",
       " 3641864  @BBCNews no one has mentioned anything about t...  NaN   NaN   en  \n",
       " 3641865  RT @DCMS: During the coronavirus pandemic, peo...  NaN   NaN   en  \n",
       " 3641866   RT @LARGESSE9826: The FBI deserve no more power!  NaN   NaN   en  \n",
       " 3641867  RT @CalebJHull: If you watch one thing on Dems...  NaN   NaN   en  \n",
       " 3641868  RT @MaziIbe_: Don’t pledge anything. Buy what’...  NaN   NaN   en  \n",
       " \n",
       " [3641869 rows x 6 columns],\n",
       "        Unnamed: 0           created_at                   id  \\\n",
       " 0               0  2020-02-28 15:44:49  1233417783175778304   \n",
       " 1               1  2020-02-28 15:44:40  1233417742520332290   \n",
       " 2               2  2020-02-28 15:44:39  1233417741027225602   \n",
       " 3               3  2020-02-28 15:44:29  1233417699264356357   \n",
       " 4               4  2020-02-28 15:44:23  1233417674274807808   \n",
       " ...           ...                  ...                  ...   \n",
       " 33169       60154  2019-12-10 11:49:59  1204367653646848000   \n",
       " 33170       60156  2019-12-10 01:33:34  1204212528810729479   \n",
       " 33171       60157  2019-12-10 01:10:03  1204206609708331009   \n",
       " 33172       60158  2019-12-03 22:57:36  1201998948950577152   \n",
       " 33173       60159  2019-12-01 03:17:00  1200977067266990080   \n",
       " \n",
       "                                                full_text  \\\n",
       " 0      also the entire swiss football league is on ho...   \n",
       " 1      world health org official: trump’s press confe...   \n",
       " 2      i mean, liberals are cheer-leading this #coron...   \n",
       " 3      under repeated questioning, pompeo refuses to ...   \n",
       " 4      #coronavirus comments now from @larry_kudlow h...   \n",
       " ...                                                  ...   \n",
       " 33169  rt @timhquotes: it's my party, you're invited!...   \n",
       " 33170  rt @timhquotes: it's my party, you're invited!...   \n",
       " 33171  it's my party, you're invited!\\n\\nps, this is ...   \n",
       " 33172  amy’s a survivor! #bariclab #pnnl #movingon #c...   \n",
       " 33173  a review of asymptomatic and sub-clinical midd...   \n",
       " \n",
       "                                     place  \n",
       " 0                                     NaN  \n",
       " 1                      Los Angeles CA USA  \n",
       " 2                               Miami, FL  \n",
       " 3                  NYC and the North Fork  \n",
       " 4      James S. Brady Press Briefing Room  \n",
       " ...                                   ...  \n",
       " 33169               The Lair of the Beast  \n",
       " 33170                                 NaN  \n",
       " 33171                    Jackson Hole, WY  \n",
       " 33172                     Chapel Hill, NC  \n",
       " 33173                                 USA  \n",
       " \n",
       " [33174 rows x 5 columns],\n",
       "                         created_at            id  \\\n",
       " 0        2020-03-26 02:52:40+00:00  1.243008e+18   \n",
       " 1        2020-03-26 09:10:44+00:00  1.243103e+18   \n",
       " 2        2020-03-27 09:50:44+00:00  1.243476e+18   \n",
       " 3        2020-03-28 06:14:13+00:00  1.243783e+18   \n",
       " 4        2020-03-28 07:28:57+00:00  1.243802e+18   \n",
       " ...                            ...           ...   \n",
       " 3455271  2020-03-24 18:37:17+00:00  1.242521e+18   \n",
       " 3455272  2020-03-25 00:13:10+00:00  1.242605e+18   \n",
       " 3455273  2020-03-25 05:58:30+00:00  1.242692e+18   \n",
       " 3455274  2020-03-26 07:52:47+00:00  1.243083e+18   \n",
       " 3455275  2020-03-26 08:19:20+00:00  1.243090e+18   \n",
       " \n",
       "                                                  full_text  geo place lang  \n",
       " 0        RT @olgaNYC1211: Retweeting this because the a...  NaN   NaN   en  \n",
       " 1        The latest The News Daily! https://t.co/pod0Z9...  NaN   NaN   en  \n",
       " 2        RT @barstoolsports: Taylor Swift Is Sending Fa...  NaN   NaN   en  \n",
       " 3        @HootPhD What the hell got into her? I don't g...  NaN   NaN   en  \n",
       " 4        RT @DrZweliMkhize: #Lockdown Update : Transpor...  NaN   NaN   en  \n",
       " ...                                                    ...  ...   ...  ...  \n",
       " 3455271  RT @charliekirk11: This is your daily reminder...  NaN   NaN   en  \n",
       " 3455272  RT @Reuters: Apple expects to start reopening ...  NaN   NaN   en  \n",
       " 3455273  RT @dbongino: TDS infected moron implying that...  NaN   NaN   en  \n",
       " 3455274  RT @jeffwellz: What I find worrying is that, e...  NaN   NaN   en  \n",
       " 3455275  RT @t_hicksnelson: COVID-19 is a cruel virus. ...  NaN   NaN   en  \n",
       " \n",
       " [3455276 rows x 6 columns],\n",
       "                         created_at            id  \\\n",
       " 0        2020-03-06 00:10:19+00:00  1.235719e+18   \n",
       " 1        2020-03-06 09:51:02+00:00  1.235865e+18   \n",
       " 2        2020-03-07 05:36:27+00:00  1.236164e+18   \n",
       " 3        2020-03-09 22:56:58+00:00  1.237150e+18   \n",
       " 4        2020-03-11 02:14:19+00:00  1.237562e+18   \n",
       " ...                            ...           ...   \n",
       " 3453079  2020-04-02 12:33:53+00:00  1.245691e+18   \n",
       " 3453080  2020-04-02 16:23:34+00:00  1.245749e+18   \n",
       " 3453081  2020-04-02 19:44:56+00:00  1.245799e+18   \n",
       " 3453082  2020-04-02 19:55:40+00:00  1.245802e+18   \n",
       " 3453083  2020-04-03 23:24:37+00:00  1.246217e+18   \n",
       " \n",
       "                                                  full_text  geo place lang  \n",
       " 0        RT @JaneLytv: 5. Unfollow the twitter account ...  NaN   NaN   en  \n",
       " 1        RT @AliyaAlwani: Coronavirus most common sympt...  NaN   NaN   en  \n",
       " 2        RT @TulsiGabbard: South Korea has the ability ...  NaN   NaN   en  \n",
       " 3        RT @BpRobertReed: O God, protect us against th...  NaN   NaN   en  \n",
       " 4        RT @tastefullytayy: Coronavirus has crossed th...  NaN   NaN   en  \n",
       " ...                                                    ...  ...   ...  ...  \n",
       " 3453079  RT @agoodfireburns: Weird right, how sending o...  NaN   NaN   en  \n",
       " 3453080  RT @ResourceDesk: Serbia: Other manipulation i...  NaN   NaN   en  \n",
       " 3453081  RT @RepRubenGallego: Tribal communities will s...  NaN   NaN   en  \n",
       " 3453082  RT @LulBit_ME: After COVID-19 ... i promise y’...  NaN   NaN   en  \n",
       " 3453083  RT @weijia: Jared Kushner is in charge of the ...  NaN   NaN   en  \n",
       " \n",
       " [3453084 rows x 6 columns],\n",
       "                         created_at            id  \\\n",
       " 0        2020-03-26 01:09:44+00:00  1.242982e+18   \n",
       " 1        2020-03-26 19:32:08+00:00  1.243259e+18   \n",
       " 2        2020-03-26 22:28:36+00:00  1.243304e+18   \n",
       " 3        2020-03-29 20:42:08+00:00  1.244364e+18   \n",
       " 4        2020-03-30 07:04:37+00:00  1.244521e+18   \n",
       " ...                            ...           ...   \n",
       " 3491466  2020-03-17 10:57:07+00:00  1.239868e+18   \n",
       " 3491467  2020-03-17 20:43:57+00:00  1.240016e+18   \n",
       " 3491468  2020-03-18 00:31:54+00:00  1.240073e+18   \n",
       " 3491469  2020-03-18 03:59:15+00:00  1.240126e+18   \n",
       " 3491470  2020-03-18 04:12:52+00:00  1.240129e+18   \n",
       " \n",
       "                                                  full_text  geo place lang  \n",
       " 0        @realDonaldTrump Georgia hospital worker with ...  NaN   NaN   en  \n",
       " 1        @MamataOfficial @RP_SanjivGoenka \\nCant this t...  NaN   NaN   en  \n",
       " 2        RT @Albion_Rover: Only the @BBCNews could come...  NaN   NaN   en  \n",
       " 3        Jefferies Group said Chief Financial Officer P...  NaN   NaN   en  \n",
       " 4        The most animal unfriendly country in the worl...  NaN   NaN   en  \n",
       " ...                                                    ...  ...   ...  ...  \n",
       " 3491466  RT @FC_Australia: FCA wish Head Coaches Ufuk T...  NaN   NaN   en  \n",
       " 3491467  RT @wojespn: Four Nets have tested positive fo...  NaN   NaN   en  \n",
       " 3491468  RT @JackMa: The first shipment of masks and co...  NaN   NaN   en  \n",
       " 3491469  RT @slpng_giants: If you live in Michigan and ...  NaN   NaN   en  \n",
       " 3491470  RT @GlennKesslerWP: This tweet was just eight ...  NaN   NaN   en  \n",
       " \n",
       " [3491471 rows x 6 columns],\n",
       "                         created_at            id  \\\n",
       " 0        2020-03-13 10:51:06+00:00  1.238417e+18   \n",
       " 1        2020-03-14 11:46:53+00:00  1.238794e+18   \n",
       " 2        2020-03-14 12:22:11+00:00  1.238803e+18   \n",
       " 3        2020-03-14 15:03:49+00:00  1.238843e+18   \n",
       " 4        2020-03-15 06:55:33+00:00  1.239083e+18   \n",
       " ...                            ...           ...   \n",
       " 3550721  2020-03-16 06:45:03+00:00  1.239443e+18   \n",
       " 3550722  2020-03-18 04:33:05+00:00  1.240134e+18   \n",
       " 3550723  2020-03-18 21:47:56+00:00  1.240395e+18   \n",
       " 3550724  2020-03-19 09:41:13+00:00  1.240574e+18   \n",
       " 3550725  2020-03-19 11:53:01+00:00  1.240607e+18   \n",
       " \n",
       "                                                  full_text  geo place lang  \n",
       " 0        RT @AgentPjr: Something is definitely wrong. T...  NaN   NaN   en  \n",
       " 1        RT @WannaBeReeceJr: niggas saw that hockey cou...  NaN   NaN   en  \n",
       " 2        RT @ZainSugieres: the legend is back and now h...  NaN   NaN   en  \n",
       " 3        RT @6ixbuzztv: Canada's first COVID-19 vaccine...  NaN   NaN   en  \n",
       " 4        RT @knyde: Girls will survive COVID-19 bc they...  NaN   NaN   en  \n",
       " ...                                                    ...  ...   ...  ...  \n",
       " 3550721  RT @DavidHenigUK: Written about government han...  NaN   NaN   en  \n",
       " 3550722  RT @ikaveri: Here's an unexpected side effect ...  NaN   NaN   en  \n",
       " 3550723  RT @shezALibra: This poor man is going to die ...  NaN   NaN   en  \n",
       " 3550724  RT @baeonda: I’m 22 years old and I tested pos...  NaN   NaN   en  \n",
       " 3550725  RT @News24: 6 months in jail for spreading fak...  NaN   NaN   en  \n",
       " \n",
       " [3550726 rows x 6 columns],\n",
       "                         created_at            id  \\\n",
       " 0        2020-03-31 11:29:06+00:00  1.244950e+18   \n",
       " 1        2020-04-01 07:17:21+00:00  1.245249e+18   \n",
       " 2        2020-04-02 05:08:20+00:00  1.245579e+18   \n",
       " 3        2020-04-02 16:36:55+00:00  1.245752e+18   \n",
       " 4        2020-04-02 21:36:25+00:00  1.245827e+18   \n",
       " ...                            ...           ...   \n",
       " 3429984  2020-04-03 18:57:23+00:00  1.246150e+18   \n",
       " 3429985  2020-04-04 01:19:47+00:00  1.246246e+18   \n",
       " 3429986  2020-01-30 12:38:27+00:00  1.222862e+18   \n",
       " 3429987  2020-01-30 17:19:45+00:00  1.222932e+18   \n",
       " 3429988  2020-02-05 07:35:52+00:00  1.224960e+18   \n",
       " \n",
       "                                                  full_text  geo place lang  \n",
       " 0        RT @mikeschussler: Unemployment in Isreal shot...  NaN   NaN   en  \n",
       " 1        RT @ramanmann1974: What has #lockdown supposed...  NaN   NaN   en  \n",
       " 2        RT @RepBobGibbs: This should surprise no one. ...  NaN   NaN   en  \n",
       " 3        This is why we need a better solution than ind...  NaN   NaN   en  \n",
       " 4        But I thought Trump loved the military https:/...  NaN   NaN   en  \n",
       " ...                                                    ...  ...   ...  ...  \n",
       " 3429984  RT @gatewaypundit: Nevada Governor Sisolak Fou...  NaN   NaN   en  \n",
       " 3429985  Wuhan lockdown led to dramatic cut in global s...  NaN   NaN   en  \n",
       " 3429986  RT @jaemrenle: LOL the 3rd coronavirus patient...  NaN   NaN   en  \n",
       " 3429987  RT @Miaa310: This coronavirus going round is n...  NaN   NaN   en  \n",
       " 3429988  BBC News - Coronavirus in Wuhan: ‘We’d rather ...  NaN   NaN   en  \n",
       " \n",
       " [3429989 rows x 6 columns],\n",
       "          Unnamed: 0                 created_at            id  \\\n",
       " 0                 2  2020-03-09 00:00:00+00:00  1.236804e+18   \n",
       " 1                 3  2020-03-09 00:00:14+00:00  1.236804e+18   \n",
       " 2                 4  2020-03-09 00:00:28+00:00  1.236804e+18   \n",
       " 3                 5  2020-03-09 00:00:36+00:00  1.236804e+18   \n",
       " 4                 8  2020-03-09 00:00:42+00:00  1.236804e+18   \n",
       " ...             ...                        ...           ...   \n",
       " 16218874   12247056  2020-03-25 23:59:58+00:00  1.242964e+18   \n",
       " 16218875   12247058  2020-03-25 23:59:59+00:00  1.242964e+18   \n",
       " 16218876   12247062  2020-03-25 23:59:59+00:00  1.242964e+18   \n",
       " 16218877   12247063  2020-03-25 23:59:59+00:00  1.242964e+18   \n",
       " 16218878   12247064  2020-03-25 23:59:59+00:00  1.242964e+18   \n",
       " \n",
       "                                                   full_text place  \n",
       " 0         during a health scare like the #coronavirusout...   NaN  \n",
       " 1         @twitter please update reporting to include fa...   NaN  \n",
       " 2         germ guardian pluggable air purifier &amp; san...   NaN  \n",
       " 3         simple math proves the chinese government is l...   NaN  \n",
       " 4         classes were suspended in the following cities...   NaN  \n",
       " ...                                                     ...   ...  \n",
       " 16218874  hello, it's me... #lockdown #thequeen #primemi...   NaN  \n",
       " 16218875  in the beginning, many of the cases followed a...   NaN  \n",
       " 16218876  ava is done with the house.  she needs some fr...   NaN  \n",
       " 16218877  anyone else notice her timeline?\\nshe tweeting...   NaN  \n",
       " 16218878  @middleageriot where's the priority focus by e...   NaN  \n",
       " \n",
       " [16218879 rows x 5 columns],\n",
       "                         created_at            id  \\\n",
       " 0        2020-03-30 05:44:15+00:00  1.244501e+18   \n",
       " 1        2020-03-30 16:53:42+00:00  1.244669e+18   \n",
       " 2        2020-03-31 08:08:31+00:00  1.244899e+18   \n",
       " 3        2020-03-31 18:38:15+00:00  1.245058e+18   \n",
       " 4        2020-04-01 14:02:26+00:00  1.245351e+18   \n",
       " ...                            ...           ...   \n",
       " 3429373  2020-03-26 17:06:51+00:00  1.243223e+18   \n",
       " 3429374  2020-03-28 00:14:26+00:00  1.243693e+18   \n",
       " 3429375  2020-03-29 08:38:49+00:00  1.244182e+18   \n",
       " 3429376  2020-03-29 21:14:31+00:00  1.244372e+18   \n",
       " 3429377  2020-03-29 23:49:10+00:00  1.244411e+18   \n",
       " \n",
       "                                                  full_text  geo  \\\n",
       " 0        Italy is Lying About Their Coronavirus Death N...  NaN   \n",
       " 1        RT @David_Moscrop: This is like me and my neig...  NaN   \n",
       " 2        RT @ANI: Congress MLA from Arunachal Pradesh, ...  NaN   \n",
       " 3                Of course he did. https://t.co/E6xp8cql7f  NaN   \n",
       " 4        Leftists are attention whores, especially cele...  NaN   \n",
       " ...                                                    ...  ...   \n",
       " 3429373  RT @HeidiNBC: Ab 16% of Ohio’s coronavirus cas...  NaN   \n",
       " 3429374  @HVlovespolitics @sciencechick1 @funder Of cou...  NaN   \n",
       " 3429375  RT @ANI: A 40-year old #Coronavirus patient ha...  NaN   \n",
       " 3429376  RT @PremiumTimesng: JUST IN: Nigeria confirms ...  NaN   \n",
       " 3429377  RT @szirinsky: It is with profound sadness tha...  NaN   \n",
       " \n",
       "                                                      place lang  \n",
       " 0                                                      NaN   en  \n",
       " 1                                                      NaN   en  \n",
       " 2                                                      NaN   en  \n",
       " 3                                                      NaN   en  \n",
       " 4        {'id': '1c67f9d9cbae7f69', 'url': 'https://api...   en  \n",
       " ...                                                    ...  ...  \n",
       " 3429373                                                NaN   en  \n",
       " 3429374                                                NaN   en  \n",
       " 3429375                                                NaN   en  \n",
       " 3429376                                                NaN   en  \n",
       " 3429377                                                NaN   en  \n",
       " \n",
       " [3429378 rows x 6 columns]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4e5d062b96f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_sorter(file):\n",
    "    df = pd.read_pickle('data/cleaned_tweet_df/'+file+'.csv')\n",
    "    for ent in tqdm(entity_list):\n",
    "        ent_df = df[df['full_text'].str.contains('|'.join(ent), na=False)]\n",
    "        ent_df.to_pickle('data/ent_dfs/'+str(ent[0])+'/'+str(file)+'_'+str(ent[0])+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8ac3bb17a57c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'file_list' is not defined"
     ]
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:01<00:00, 16.22it/s]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('small_tweet_set_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:30<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (3,4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "100%|██████████| 21/21 [01:30<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:31<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:30<00:00,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:30<00:00,  4.30s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:34<00:00,  4.50s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:29<00:00,  4.28s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:29<00:00,  4.24s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_chunks_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [03:35<00:00, 10.28s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_kaggle1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [02:40<00:00,  7.66s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_kaggle2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [01:51<00:00,  5.32s/it]\n"
     ]
    }
   ],
   "source": [
    "entity_sorter('clean_kaggle3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/china/small_tweet_set_cleaned_china.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12475, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:05<01:52,  5.63s/it]\u001b[A\n",
      " 10%|▉         | 2/21 [00:10<01:42,  5.40s/it]\u001b[A\n",
      " 14%|█▍        | 3/21 [00:15<01:33,  5.21s/it]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:20<01:27,  5.12s/it]\u001b[A\n",
      " 24%|██▍       | 5/21 [00:24<01:16,  4.81s/it]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:28<01:11,  4.75s/it]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:34<01:09,  4.99s/it]\u001b[A\n",
      " 38%|███▊      | 8/21 [00:39<01:05,  5.02s/it]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:43<00:58,  4.85s/it]\u001b[A\n",
      " 48%|████▊     | 10/21 [00:45<00:43,  3.97s/it]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:52<00:46,  4.64s/it]\u001b[A\n",
      " 57%|█████▋    | 12/21 [00:54<00:34,  3.88s/it]\u001b[A\n",
      " 62%|██████▏   | 13/21 [00:56<00:27,  3.39s/it]\u001b[A\n",
      " 67%|██████▋   | 14/21 [00:58<00:21,  3.01s/it]\u001b[A\n",
      " 71%|███████▏  | 15/21 [01:06<00:26,  4.37s/it]\u001b[A\n",
      " 76%|███████▌  | 16/21 [01:08<00:19,  3.88s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [01:13<00:17,  4.26s/it]\u001b[A\n",
      " 86%|████████▌ | 18/21 [01:19<00:14,  4.70s/it]\u001b[A\n",
      " 90%|█████████ | 19/21 [01:24<00:09,  4.60s/it]\u001b[A\n",
      " 95%|█████████▌| 20/21 [01:28<00:04,  4.62s/it]\u001b[A\n",
      "100%|██████████| 21/21 [01:33<00:00,  4.47s/it]\u001b[A\n",
      "  8%|▊         | 1/12 [01:41<18:38, 101.67s/it]//anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (3,4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:05<01:49,  5.46s/it]\u001b[A\n",
      " 10%|▉         | 2/21 [00:10<01:40,  5.30s/it]\u001b[A\n",
      " 14%|█▍        | 3/21 [00:15<01:33,  5.17s/it]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:20<01:26,  5.10s/it]\u001b[A\n",
      " 24%|██▍       | 5/21 [00:24<01:16,  4.79s/it]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:29<01:12,  4.85s/it]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:35<01:11,  5.13s/it]\u001b[A\n",
      " 38%|███▊      | 8/21 [00:40<01:06,  5.12s/it]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:44<00:58,  4.85s/it]\u001b[A\n",
      " 48%|████▊     | 10/21 [00:46<00:43,  3.98s/it]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:52<00:44,  4.49s/it]\u001b[A\n",
      " 57%|█████▋    | 12/21 [00:54<00:33,  3.77s/it]\u001b[A\n",
      " 62%|██████▏   | 13/21 [00:56<00:26,  3.29s/it]\u001b[A\n",
      " 67%|██████▋   | 14/21 [00:58<00:20,  2.90s/it]\u001b[A\n",
      " 71%|███████▏  | 15/21 [01:05<00:25,  4.21s/it]\u001b[A\n",
      " 76%|███████▌  | 16/21 [01:08<00:18,  3.77s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [01:13<00:16,  4.13s/it]\u001b[A\n",
      " 86%|████████▌ | 18/21 [01:18<00:13,  4.54s/it]\u001b[A\n",
      " 90%|█████████ | 19/21 [01:22<00:08,  4.44s/it]\u001b[A\n",
      " 95%|█████████▌| 20/21 [01:27<00:04,  4.47s/it]\u001b[A\n",
      "100%|██████████| 21/21 [01:32<00:00,  4.40s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [03:21<16:51, 101.19s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|▉         | 2/21 [00:00<00:01, 11.85it/s]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:00<00:01, 12.04it/s]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:00<00:01, 12.33it/s]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:00<00:01, 11.39it/s]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:00<00:01, 11.99it/s]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:00<00:00, 12.87it/s]\u001b[A\n",
      " 62%|██████▏   | 13/21 [00:01<00:00, 12.67it/s]\u001b[A\n",
      " 71%|███████▏  | 15/21 [00:01<00:00, 12.46it/s]\u001b[A\n",
      " 81%|████████  | 17/21 [00:01<00:00, 13.40it/s]\u001b[A\n",
      " 90%|█████████ | 19/21 [00:01<00:00, 12.68it/s]\u001b[A\n",
      "100%|██████████| 21/21 [00:01<00:00, 12.63it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [03:23<10:42, 71.37s/it] \n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:05<01:50,  5.55s/it]\u001b[A\n",
      " 10%|▉         | 2/21 [00:10<01:41,  5.34s/it]\u001b[A\n",
      " 14%|█▍        | 3/21 [00:15<01:32,  5.14s/it]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:20<01:26,  5.07s/it]\u001b[A\n",
      " 24%|██▍       | 5/21 [00:24<01:16,  4.76s/it]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:29<01:12,  4.84s/it]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:34<01:09,  4.98s/it]\u001b[A\n",
      " 38%|███▊      | 8/21 [00:39<01:04,  4.96s/it]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:43<00:56,  4.75s/it]\u001b[A\n",
      " 48%|████▊     | 10/21 [00:45<00:42,  3.89s/it]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:51<00:44,  4.47s/it]\u001b[A\n",
      " 57%|█████▋    | 12/21 [00:53<00:33,  3.75s/it]\u001b[A\n",
      " 62%|██████▏   | 13/21 [00:55<00:26,  3.26s/it]\u001b[A\n",
      " 67%|██████▋   | 14/21 [00:57<00:20,  2.88s/it]\u001b[A\n",
      " 71%|███████▏  | 15/21 [01:04<00:25,  4.19s/it]\u001b[A\n",
      " 76%|███████▌  | 16/21 [01:07<00:18,  3.80s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [01:12<00:16,  4.16s/it]\u001b[A\n",
      " 86%|████████▌ | 18/21 [01:18<00:13,  4.58s/it]\u001b[A\n",
      " 90%|█████████ | 19/21 [01:22<00:08,  4.45s/it]\u001b[A\n",
      " 95%|█████████▌| 20/21 [01:26<00:04,  4.50s/it]\u001b[A\n",
      "100%|██████████| 21/21 [01:31<00:00,  4.37s/it]\u001b[A\n",
      " 33%|███▎      | 4/12 [05:03<10:39, 79.91s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 1/21 [00:05<01:49,  5.49s/it]\u001b[A\n",
      " 10%|▉         | 2/21 [00:10<01:40,  5.29s/it]\u001b[A\n",
      " 14%|█▍        | 3/21 [00:15<01:32,  5.13s/it]\u001b[A\n",
      " 19%|█▉        | 4/21 [00:19<01:25,  5.03s/it]\u001b[A\n",
      " 24%|██▍       | 5/21 [00:23<01:15,  4.73s/it]\u001b[A\n",
      " 29%|██▊       | 6/21 [00:28<01:10,  4.67s/it]\u001b[A\n",
      " 33%|███▎      | 7/21 [00:33<01:08,  4.87s/it]\u001b[A\n",
      " 38%|███▊      | 8/21 [00:38<01:03,  4.92s/it]\u001b[A\n",
      " 43%|████▎     | 9/21 [00:43<00:56,  4.71s/it]\u001b[A\n",
      " 48%|████▊     | 10/21 [00:44<00:42,  3.86s/it]\u001b[A\n",
      " 52%|█████▏    | 11/21 [00:50<00:44,  4.43s/it]\u001b[A\n",
      " 57%|█████▋    | 12/21 [00:52<00:33,  3.71s/it]\u001b[A\n",
      " 62%|██████▏   | 13/21 [00:54<00:26,  3.26s/it]\u001b[A\n",
      " 67%|██████▋   | 14/21 [00:56<00:20,  2.88s/it]\u001b[A\n",
      " 71%|███████▏  | 15/21 [01:04<00:25,  4.22s/it]\u001b[A\n",
      " 76%|███████▌  | 16/21 [01:07<00:19,  3.82s/it]\u001b[A\n",
      " 81%|████████  | 17/21 [01:12<00:16,  4.18s/it]\u001b[A\n",
      " 86%|████████▌ | 18/21 [01:17<00:13,  4.60s/it]\u001b[A\n",
      " 90%|█████████ | 19/21 [01:21<00:08,  4.48s/it]\u001b[A\n",
      " 95%|█████████▌| 20/21 [01:26<00:04,  4.51s/it]\u001b[A\n",
      "100%|██████████| 21/21 [01:31<00:00,  4.36s/it]\u001b[A\n",
      " 42%|████▏     | 5/12 [06:42<09:23, 80.50s/it]\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-18ce4ccf4303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mentity_sorter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-1aed67c544e7>\u001b[0m in \u001b[0;36mentity_sorter\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mentity_sorter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/cleaned_tweet_df/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ment_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ment_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/ent_dfs/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(file_list):\n",
    "    entity_sorter(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_folders = []\n",
    "\n",
    "def folder_grabber(directory):\n",
    "    folders = os.listdir(directory)\n",
    "    for folder in folders:\n",
    "        #folder = str(folder.replace('.csv','')\n",
    "        ent_folders.append(folder)\n",
    "\n",
    "folder_grabber('data/ent_dfs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['usa',\n",
       " 'cdc',\n",
       " '.DS_Store',\n",
       " 'nba',\n",
       " 'spain',\n",
       " 'nhs',\n",
       " 'fauci',\n",
       " 'boris',\n",
       " 'china',\n",
       " 'who',\n",
       " 'nfl',\n",
       " 'italy',\n",
       " 'fifa',\n",
       " 'obama',\n",
       " 'whitehouse',\n",
       " 'nhl',\n",
       " 'eu',\n",
       " 'congress',\n",
       " 'trump',\n",
       " 'mlb',\n",
       " 'nyc',\n",
       " 'pelosi']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_df_joiner(file_list):\n",
    "    df = pd.concat(file_list, ignore_index=True)\n",
    "    df = df[['created_at', 'id', 'full_text', 'place']]\n",
    "    df.created_at = pd.to_datetime(df.created_at, utc=True)\n",
    "    df['month'] = df.created_at.dt.month\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 30.32it/s]\n"
     ]
    }
   ],
   "source": [
    "china_df = []\n",
    "\n",
    "for file in tqdm(glob.glob('data/ent_dfs/china/*')):\n",
    "    china_df.append(pd.read_pickle(file))\n",
    "\n",
    "china_df = ent_df_joiner(china_df)\n",
    "\n",
    "china_df.to_pickle('data/joined_ent_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ent_folders:\n",
    "    list_name = str(folder)+'_df'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00,  7.10it/s]\n"
     ]
    }
   ],
   "source": [
    "trump_df = []\n",
    "bad_trump_df = []\n",
    "for file in tqdm(glob.glob('data/ent_dfs/trump/*')):\n",
    "    try:\n",
    "        trump_df.append(pd.read_pickle(file))\n",
    "    except:\n",
    "        bad_trump_df.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_trump_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-7b43ffe9a86f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ment_df_joiner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrump_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#china_df.to_pickle('data/joined_ent_df/china_df.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-107-a4f4ea837501>\u001b[0m in \u001b[0;36ment_df_joiner\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#    return df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/joined_ent_df/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "ent_df_joiner(trump_df)\n",
    "#china_df.to_pickle('data/joined_ent_df/china_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_test = pd.read_pickle('data/joined_ent_df/china_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>place</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-05 00:00:08+00:00</td>\n",
       "      <td>1246588394622287872</td>\n",
       "      <td>during q1, the #coronavirus brought parts of c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-05 00:00:23+00:00</td>\n",
       "      <td>1246588458002452480</td>\n",
       "      <td>na china chop meat\\nbut na we de wash hand \\ni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-05 00:00:36+00:00</td>\n",
       "      <td>1246588512369074176</td>\n",
       "      <td>@rbsw @dwnews @bonnieglaser @dktatlow #coronav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-05 00:00:37+00:00</td>\n",
       "      <td>1246588516173111296</td>\n",
       "      <td>@monachareneppc yeah it is definitely china’s ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-05 00:00:45+00:00</td>\n",
       "      <td>1246588550881165312</td>\n",
       "      <td>@ddgaddis saluti, you can read it here: @johnb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0 2020-04-05 00:00:08+00:00  1246588394622287872   \n",
       "1 2020-04-05 00:00:23+00:00  1246588458002452480   \n",
       "2 2020-04-05 00:00:36+00:00  1246588512369074176   \n",
       "3 2020-04-05 00:00:37+00:00  1246588516173111296   \n",
       "4 2020-04-05 00:00:45+00:00  1246588550881165312   \n",
       "\n",
       "                                           full_text place  month  \n",
       "0  during q1, the #coronavirus brought parts of c...   NaN      4  \n",
       "1  na china chop meat\\nbut na we de wash hand \\ni...   NaN      4  \n",
       "2  @rbsw @dwnews @bonnieglaser @dktatlow #coronav...   NaN      4  \n",
       "3  @monachareneppc yeah it is definitely china’s ...   NaN      4  \n",
       "4  @ddgaddis saluti, you can read it here: @johnb...   NaN      4  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699359, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699359 entries, 0 to 699358\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   created_at  699359 non-null  object\n",
      " 1   id          699359 non-null  object\n",
      " 2   full_text   699359 non-null  object\n",
      " 3   place       26459 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 21.3+ MB\n"
     ]
    }
   ],
   "source": [
    "china_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_test['id'] = china_test.id.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699359 entries, 0 to 699358\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   created_at  699359 non-null  object\n",
      " 1   id          699359 non-null  int64 \n",
      " 2   full_text   699359 non-null  object\n",
      " 3   place       26459 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 21.3+ MB\n"
     ]
    }
   ],
   "source": [
    "china_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "china_test['created_at'] = pd.to_datetime(china_test.created_at, utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_test = china_test[1800:1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "small_test['created_at'] = pd.to_datetime(small_test.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2020-04-05 05:38:05+00:00</td>\n",
       "      <td>1246673443170508805</td>\n",
       "      <td>don't know why but #covid_19 seems the end of ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>2020-04-05 05:38:27+00:00</td>\n",
       "      <td>1246673535151427584</td>\n",
       "      <td>430,000 people arrived in the usa from china a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2020-04-05 05:38:28+00:00</td>\n",
       "      <td>1246673540008443904</td>\n",
       "      <td>#coronavirus worldwide: \\nus: 311,600\\nspain: ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>2020-04-05 05:38:35+00:00</td>\n",
       "      <td>1246673570027261952</td>\n",
       "      <td>#covid19 \\n#italy's #cat #test is #negative ev...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>2020-04-05 05:39:01+00:00</td>\n",
       "      <td>1246673679326429186</td>\n",
       "      <td>mainland china has now reported a total of 81,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at                   id  \\\n",
       "1800 2020-04-05 05:38:05+00:00  1246673443170508805   \n",
       "1801 2020-04-05 05:38:27+00:00  1246673535151427584   \n",
       "1802 2020-04-05 05:38:28+00:00  1246673540008443904   \n",
       "1803 2020-04-05 05:38:35+00:00  1246673570027261952   \n",
       "1804 2020-04-05 05:39:01+00:00  1246673679326429186   \n",
       "\n",
       "                                              full_text place  \n",
       "1800  don't know why but #covid_19 seems the end of ...   NaN  \n",
       "1801  430,000 people arrived in the usa from china a...   NaN  \n",
       "1802  #coronavirus worldwide: \\nus: 311,600\\nspain: ...   NaN  \n",
       "1803  #covid19 \\n#italy's #cat #test is #negative ev...   NaN  \n",
       "1804  mainland china has now reported a total of 81,...   NaN  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-05 00:00:08+00:00</td>\n",
       "      <td>1246588394622287872</td>\n",
       "      <td>during q1, the #coronavirus brought parts of c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-05 00:00:23+00:00</td>\n",
       "      <td>1246588458002452480</td>\n",
       "      <td>na china chop meat\\nbut na we de wash hand \\ni...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-05 00:00:36+00:00</td>\n",
       "      <td>1246588512369074176</td>\n",
       "      <td>@rbsw @dwnews @bonnieglaser @dktatlow #coronav...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-05 00:00:37+00:00</td>\n",
       "      <td>1246588516173111296</td>\n",
       "      <td>@monachareneppc yeah it is definitely china’s ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-05 00:00:45+00:00</td>\n",
       "      <td>1246588550881165312</td>\n",
       "      <td>@ddgaddis saluti, you can read it here: @johnb...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at                   id  \\\n",
       "0 2020-04-05 00:00:08+00:00  1246588394622287872   \n",
       "1 2020-04-05 00:00:23+00:00  1246588458002452480   \n",
       "2 2020-04-05 00:00:36+00:00  1246588512369074176   \n",
       "3 2020-04-05 00:00:37+00:00  1246588516173111296   \n",
       "4 2020-04-05 00:00:45+00:00  1246588550881165312   \n",
       "\n",
       "                                           full_text place  \n",
       "0  during q1, the #coronavirus brought parts of c...   NaN  \n",
       "1  na china chop meat\\nbut na we de wash hand \\ni...   NaN  \n",
       "2  @rbsw @dwnews @bonnieglaser @dktatlow #coronav...   NaN  \n",
       "3  @monachareneppc yeah it is definitely china’s ...   NaN  \n",
       "4  @ddgaddis saluti, you can read it here: @johnb...   NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
